{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "import pywt\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import fastcluster\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from text_processor import MDB, text_process\n",
    "from utils import load_obj, dump_obj, progress\n",
    "from timeseries_utils import *\n",
    "from metrics import *\n",
    "from pyculiarity import detect_ts\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "from geopy.distance import vincenty\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from meta import geodata\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database\n"
     ]
    }
   ],
   "source": [
    "md = MDB('tweets')\n",
    "city = 'Miami'\n",
    "mxscl = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4005 documents\n",
      "querying took 0:00:01.176305\n",
      "100%\n",
      "\n",
      "retrieval and processing took 0:00:01.907505\n"
     ]
    }
   ],
   "source": [
    "cur = md.get_last(city, days=0, hours=4)\n",
    "prc, st, en = process_batch(cur, geo=True, fsw=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = [t['words'] for t in prc if len(list_intersection(t['words'],b1))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(\"4 Pennsilvanya\")\n",
    "print(location.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md.client.local.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_at': datetime.datetime(2016, 4, 1, 22, 3, 51),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'bore', u'as', u'all', u'hell']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 54),\n",
       "  'geo': (0, [-80.428181999999993, 25.610864499999998]),\n",
       "  'words': [u'when',\n",
       "   u'you',\n",
       "   u'tri',\n",
       "   u'click',\n",
       "   u'on',\n",
       "   u'your',\n",
       "   u'boy',\n",
       "   u'caus',\n",
       "   u'you',\n",
       "   u'wanna',\n",
       "   u'get',\n",
       "   u'your',\n",
       "   u'shit',\n",
       "   u'done',\n",
       "   u'and',\n",
       "   u'they',\n",
       "   u'say',\n",
       "   u'il',\n",
       "   u'take',\n",
       "   u'you',\n",
       "   u'dumbi',\n",
       "   u'lol',\n",
       "   u'#squad']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 54),\n",
       "  'geo': (0, [-80.233328499999999, 25.782353499999999]),\n",
       "  'words': [u'friday',\n",
       "   u'friday',\n",
       "   u'friiiday',\n",
       "   u'what',\n",
       "   u'to',\n",
       "   u'do',\n",
       "   u'what',\n",
       "   u'to',\n",
       "   u'do',\n",
       "   u'what',\n",
       "   u'to',\n",
       "   u'doooo']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 55),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'scortworkz',\n",
       "   u'froggindirti',\n",
       "   u'ohhhh',\n",
       "   u'i',\n",
       "   u'know',\n",
       "   u'it',\n",
       "   u'gurlll']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 56),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'ugh']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 57),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'jpwilloughbi',\n",
       "   u'subedew',\n",
       "   u'seanhann',\n",
       "   u'newtgingrich',\n",
       "   u'reinc',\n",
       "   u'realdonaldtrump']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 57),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'#thiscrewrocksallyearlong',\n",
       "   u'stallionteam',\n",
       "   u'simeon20112',\n",
       "   u'dutch2haz',\n",
       "   u'aftereight13',\n",
       "   u'vivaciousstar2',\n",
       "   u'sweetorsassy90',\n",
       "   u'claudytheartist']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 58),\n",
       "  'geo': (0, [-80.169802500000003, 25.935641499999999]),\n",
       "  'words': [u'how',\n",
       "   u'can',\n",
       "   u'one',\n",
       "   u'ear',\n",
       "   u'be',\n",
       "   u'so',\n",
       "   u'crispi',\n",
       "   u'sunburnt',\n",
       "   u'about',\n",
       "   u'to',\n",
       "   u'fall',\n",
       "   u'off',\n",
       "   u'and',\n",
       "   u'the',\n",
       "   u'other',\n",
       "   u'one',\n",
       "   u'look',\n",
       "   u'like',\n",
       "   u'snow',\n",
       "   u'how',\n",
       "   u'i',\n",
       "   u'just',\n",
       "   u'wanna',\n",
       "   u'know']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 3, 58),\n",
       "  'geo': (0, [-80.34711999999999, 25.671986]),\n",
       "  'words': [u'you',\n",
       "   u'got',\n",
       "   u'a',\n",
       "   u'fast',\n",
       "   u'car',\n",
       "   u'is',\n",
       "   u'it',\n",
       "   u'fast',\n",
       "   u'enough',\n",
       "   u'so',\n",
       "   u'we',\n",
       "   u'can',\n",
       "   u'fli',\n",
       "   u'away']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 1),\n",
       "  'geo': (0, [-80.249772500000006, 26.270260999999998]),\n",
       "  'words': [u'you',\n",
       "   u're',\n",
       "   u'not',\n",
       "   u'a',\n",
       "   u'judgment',\n",
       "   u'jerk',\n",
       "   u'april',\n",
       "   u'fool']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 1),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'me']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 1),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'tu', u'ere', u'now', u'on', u'itun', u'amp', u'spotifi']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 3),\n",
       "  'geo': (1, [-80.16988039, 26.25139737]),\n",
       "  'words': [u'ja', u'field', u'trip', u'#tuesday', u'ja', u'financ', u'park']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 3),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'i', u'm', u'hungri', u'too']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 7),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'yo',\n",
       "   u'wtf',\n",
       "   u'i',\n",
       "   u'wanna',\n",
       "   u'wear',\n",
       "   u'yeezi',\n",
       "   u'while',\n",
       "   u'perform',\n",
       "   u'surgeri',\n",
       "   u'you',\n",
       "   u're',\n",
       "   u'a',\n",
       "   u'legend',\n",
       "   u'therealdrmiami']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 7),\n",
       "  'geo': (0, [-76.593942999999996, 24.074967000000001]),\n",
       "  'words': [u'i',\n",
       "   u'rlli',\n",
       "   u'dunno',\n",
       "   u'thi',\n",
       "   u'person',\n",
       "   u'that',\n",
       "   u'add',\n",
       "   u'me',\n",
       "   u'on',\n",
       "   u'sc']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 7),\n",
       "  'geo': (0, [-80.134985999999998, 26.3739755]),\n",
       "  'words': [u'mattybrap', u'what', u'the', u'hell', u'is', u'thi']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 7),\n",
       "  'geo': (1, [-81.57919477, 28.41864918]),\n",
       "  'words': [u'i',\n",
       "   u'could',\n",
       "   u'get',\n",
       "   u'lost',\n",
       "   u'in',\n",
       "   u'tomorrowland',\n",
       "   u'all',\n",
       "   u'day',\n",
       "   u'#waltdisneyworld',\n",
       "   u'#disneyworld',\n",
       "   u'#disneyparks']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 8),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'luci', u'buffet', u'ha', u'noth', u'on', u'hilari']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 8),\n",
       "  'geo': (0, [-80.327998500000007, 26.027889500000001]),\n",
       "  'words': [u'thi',\n",
       "   u'nigga',\n",
       "   u'swear',\n",
       "   u'he',\n",
       "   u'ha',\n",
       "   u'game',\n",
       "   u'but',\n",
       "   u'you',\n",
       "   u'be',\n",
       "   u'in',\n",
       "   u'my',\n",
       "   u'bestfriend',\n",
       "   u'phone']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 8),\n",
       "  'geo': (0, [-80.233328499999999, 25.782353499999999]),\n",
       "  'words': [u'thi',\n",
       "   u'man',\n",
       "   u'took',\n",
       "   u'cancer',\n",
       "   u'donat',\n",
       "   u'for',\n",
       "   u'hi',\n",
       "   u'kid',\n",
       "   u'and',\n",
       "   u'use',\n",
       "   u'it',\n",
       "   u'on',\n",
       "   u'prostitut',\n",
       "   u'and',\n",
       "   u'drug',\n",
       "   u'don',\n",
       "   u't',\n",
       "   u'make',\n",
       "   u'me',\n",
       "   u'tell',\n",
       "   u'the',\n",
       "   u'whole',\n",
       "   u'truth',\n",
       "   u'leav',\n",
       "   u'me',\n",
       "   u'alon']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 10),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'oh']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 12),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'same']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 12),\n",
       "  'geo': (1, [-81.3892733, 28.79441498]),\n",
       "  'words': [u'nosso',\n",
       "   u'campeo',\n",
       "   u'fazendo',\n",
       "   u'gol',\n",
       "   u'orlando',\n",
       "   u'citi',\n",
       "   u'youth',\n",
       "   u'soccer',\n",
       "   u'complex']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 13),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 13),\n",
       "  'geo': (0, [-80.285189000000003, 26.078170499999999]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 14),\n",
       "  'geo': (0, [-80.304662500000006, 25.857731999999999]),\n",
       "  'words': [u'patient',\n",
       "   u'wait',\n",
       "   u'for',\n",
       "   u'schoolboy',\n",
       "   u'q',\n",
       "   u'to',\n",
       "   u'drop',\n",
       "   u'some',\n",
       "   u'more']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 13),\n",
       "  'geo': (0, [-80.169802500000003, 25.935641499999999]),\n",
       "  'words': [u'weak', u'asf']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 17),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'probabl', u'whi', u'i', u'm', u'get', u'cranki']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 17),\n",
       "  'geo': (0, [-80.401724999999999, 26.103362000000001]),\n",
       "  'words': [u'respons',\n",
       "   u'govern',\n",
       "   u'protect',\n",
       "   u'the',\n",
       "   u'less',\n",
       "   u'fortun',\n",
       "   u'and',\n",
       "   u'promot',\n",
       "   u'equial',\n",
       "   u'of',\n",
       "   u'opportun',\n",
       "   u'for',\n",
       "   u'all',\n",
       "   u'the',\n",
       "   u'citizen',\n",
       "   u'#feelthebern',\n",
       "   u'#notmeus']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 18),\n",
       "  'geo': (0, [-80.285189000000003, 26.078170499999999]),\n",
       "  'words': [u'angeliqu', u'is', u'a', u'savag']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 19),\n",
       "  'geo': (0, [-80.294892500000003, 26.1566185]),\n",
       "  'words': [u'ni',\n",
       "   u'en',\n",
       "   u'twitter',\n",
       "   u'ni',\n",
       "   u'en',\n",
       "   u'ninguna',\n",
       "   u'part',\n",
       "   u'me',\n",
       "   u'creo',\n",
       "   u'la',\n",
       "   u'yanke',\n",
       "   u'soy',\n",
       "   u'latina',\n",
       "   u'y',\n",
       "   u'amo',\n",
       "   u'lo',\n",
       "   u'rico',\n",
       "   u'que',\n",
       "   u'es',\n",
       "   u'hablar',\n",
       "   u'perfecto',\n",
       "   u'espaol',\n",
       "   u'y',\n",
       "   u'por',\n",
       "   u'respet',\n",
       "   u'a',\n",
       "   u'mi',\n",
       "   u'entorno']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 20),\n",
       "  'geo': (0, [-80.134985999999998, 26.3739755]),\n",
       "  'words': [u'thi', u'should', u'not', u'exist']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 19),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 21),\n",
       "  'geo': (0, [-80.233698000000004, 25.838881999999998]),\n",
       "  'words': [u'gotmy3strip',\n",
       "   u'lol',\n",
       "   u'nah',\n",
       "   u'don',\n",
       "   u't',\n",
       "   u'get',\n",
       "   u'lock',\n",
       "   u'up']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 21),\n",
       "  'geo': (1, [-80.1341, 25.813]),\n",
       "  'words': [u'right',\n",
       "   u'babe',\n",
       "   u'#stonebrewing',\n",
       "   u'#craftbeer',\n",
       "   u'#craftbeerporn',\n",
       "   u'#arrogantbastard',\n",
       "   u'#vacation',\n",
       "   u'#beerlover']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 22),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'i', u'want', u'to', u'do', u'some', u'crazi', u'makeup', u'rn']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 22),\n",
       "  'geo': (0, [-80.34711999999999, 25.671986]),\n",
       "  'words': [u'my',\n",
       "   u'boss',\n",
       "   u'liter',\n",
       "   u'ha',\n",
       "   u'a',\n",
       "   u'whole',\n",
       "   u'folder',\n",
       "   u'full',\n",
       "   u'of',\n",
       "   u'ticket',\n",
       "   u'i',\n",
       "   u'had',\n",
       "   u'to',\n",
       "   u'sign',\n",
       "   u'him',\n",
       "   u'up',\n",
       "   u'for',\n",
       "   u'traffic',\n",
       "   u'school']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 23),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': ['#jokerwashere']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 24),\n",
       "  'geo': (0, [-80.233328499999999, 25.782353499999999]),\n",
       "  'words': [u'atlet', u'pijamayla', u'ktm', u'bakkal', u'aryorum', u'amk']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 22),\n",
       "  'geo': (0, [-80.162601999999993, 25.696937500000004]),\n",
       "  'words': [u'discuss', u'amongst', u'yourselv']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 24),\n",
       "  'geo': (0, [-80.132962499999991, 25.816965500000002]),\n",
       "  'words': [u'im',\n",
       "   u'def',\n",
       "   u'grandpa',\n",
       "   u'saint',\n",
       "   u'dougla',\n",
       "   u'spacegirlgemmi',\n",
       "   u'hbu']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 25),\n",
       "  'geo': (0, [-80.227328499999999, 26.389733]),\n",
       "  'words': [u'just',\n",
       "   u'anoth',\n",
       "   u'reason',\n",
       "   u'i',\n",
       "   u'can',\n",
       "   u't',\n",
       "   u'wait',\n",
       "   u'to',\n",
       "   u'leav',\n",
       "   u'boca']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 26),\n",
       "  'geo': (0, [-76.593942999999996, 24.074967000000001]),\n",
       "  'words': [u'uspismia', u'job', u'well', u'done']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 26),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'pawserv',\n",
       "   u'aridavidusa',\n",
       "   u'aclu',\n",
       "   u'instapundit',\n",
       "   u'realdonaldtrump',\n",
       "   u'tedcruz',\n",
       "   u'cnn',\n",
       "   u'abc',\n",
       "   u'nbc',\n",
       "   u'drudgereport',\n",
       "   u'the',\n",
       "   u'law',\n",
       "   u'of',\n",
       "   u'unintend',\n",
       "   u'consequ']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 26),\n",
       "  'geo': (0, [-80.353332499999993, 25.772288]),\n",
       "  'words': [u'thank', u'to', u'present', u'colleg', u'for', u'the', u'offer']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 28),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'so',\n",
       "   u'blow',\n",
       "   u'that',\n",
       "   u'someon',\n",
       "   u'ruin',\n",
       "   u'grey',\n",
       "   u'for',\n",
       "   u'me']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 28),\n",
       "  'geo': (0, [-80.304662500000006, 25.857731999999999]),\n",
       "  'words': [u'today', u'wa', u'so', u'fuck', u'shitti']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 28),\n",
       "  'geo': (0, [-80.122355499999998, 26.301197999999999]),\n",
       "  'words': [u'soapsindepthabc',\n",
       "   u'generalhospit',\n",
       "   u'the',\n",
       "   u'quartermain',\n",
       "   u'love',\n",
       "   u'them']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 30),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'gimmiethatloot']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 34),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'politico']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 36),\n",
       "  'geo': (0, [-80.138645499999996, 26.251895000000001]),\n",
       "  'words': [u'i',\n",
       "   u'been',\n",
       "   u'all',\n",
       "   u'around',\n",
       "   u'the',\n",
       "   u'globe',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'like',\n",
       "   u'a',\n",
       "   u'god',\n",
       "   u'how',\n",
       "   u'they',\n",
       "   u'treat',\n",
       "   u'me']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 36),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'loganpaul',\n",
       "   u'me',\n",
       "   u'becaus',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'your',\n",
       "   u'birthday',\n",
       "   u'today',\n",
       "   u'have',\n",
       "   u'a',\n",
       "   u'great',\n",
       "   u'birthday',\n",
       "   u'love',\n",
       "   u'and',\n",
       "   u'don',\n",
       "   u't',\n",
       "   u'let',\n",
       "   u'anyon',\n",
       "   u'prank',\n",
       "   u'you']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (1, [-81.5493554, 28.36798902]),\n",
       "  'words': [u'she',\n",
       "   u'warn',\n",
       "   u'him',\n",
       "   u'not',\n",
       "   u'to',\n",
       "   u'be',\n",
       "   u'deceiv',\n",
       "   u'by',\n",
       "   u'appear',\n",
       "   u'for',\n",
       "   u'beauti',\n",
       "   u'is',\n",
       "   u'found',\n",
       "   u'within']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'when',\n",
       "   u'peopl',\n",
       "   u'think',\n",
       "   u'about',\n",
       "   u'whether',\n",
       "   u'they',\n",
       "   u'are',\n",
       "   u'truli',\n",
       "   u'#prolife',\n",
       "   u'it',\n",
       "   u'doesn',\n",
       "   u't',\n",
       "   u'matter',\n",
       "   u'how',\n",
       "   u'mani',\n",
       "   u'articl',\n",
       "   u'you',\n",
       "   u'post',\n",
       "   u'or',\n",
       "   u'battl',\n",
       "   u'you',\n",
       "   u'fight',\n",
       "   u'onli',\n",
       "   u'#personhood']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (0, [-80.233328499999999, 25.782353499999999]),\n",
       "  'words': [u'haileejefferi', u'yasss', u'girl']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (0, [-80.407424999999989, 25.7074395]),\n",
       "  'words': [u'as',\n",
       "   u'much',\n",
       "   u'as',\n",
       "   u'i',\n",
       "   u'love',\n",
       "   u'ff',\n",
       "   u'300',\n",
       "   u'for',\n",
       "   u'a',\n",
       "   u'collector',\n",
       "   u'hurt',\n",
       "   u'now',\n",
       "   u'if',\n",
       "   u'it',\n",
       "   u'wa',\n",
       "   u'kh',\n",
       "   u'3',\n",
       "   u'then',\n",
       "   u'ye',\n",
       "   u'take',\n",
       "   u'my',\n",
       "   u'soul',\n",
       "   u'#gamerproblems']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (0, [-80.353332499999993, 25.772288]),\n",
       "  'words': [u'officialabn',\n",
       "   u'whi',\n",
       "   u'you',\n",
       "   u'give',\n",
       "   u'me',\n",
       "   u'your',\n",
       "   u'grandma',\n",
       "   u'address',\n",
       "   u'instead',\n",
       "   u'bitch',\n",
       "   u'ass',\n",
       "   u'didn',\n",
       "   u't',\n",
       "   u'even',\n",
       "   u'put',\n",
       "   u'the',\n",
       "   u'apart']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 37),\n",
       "  'geo': (1, [-82.26185197, 26.75082192]),\n",
       "  'words': [u'thank',\n",
       "   u'boca',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'been',\n",
       "   u'real',\n",
       "   u'#bocagrande',\n",
       "   u'gasparilla',\n",
       "   u'island']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 38),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'yea']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 38),\n",
       "  'geo': (0, [-80.313674499999991, 25.712215499999999]),\n",
       "  'words': [u'natalieochoa6', u'lmfao']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 38),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'my', u'brother', u'call', u'me', u'bubbl']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 39),\n",
       "  'geo': (0, [-80.149172500000006, 26.150368]),\n",
       "  'words': [u'nhdogmom', u'caus', u'berni', u'is', u'annoy']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 41),\n",
       "  'geo': (1, [-80.323, 25.732]),\n",
       "  'words': [u'the',\n",
       "   u'three',\n",
       "   u'of',\n",
       "   u'you',\n",
       "   u'singl',\n",
       "   u'handedli',\n",
       "   u'made',\n",
       "   u'us',\n",
       "   u'a',\n",
       "   u'basketbal',\n",
       "   u'town',\n",
       "   u'kingjam',\n",
       "   u'dwyanewad',\n",
       "   u'chrisbosh']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 42),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'final', u'got', u'my', u'prom', u'dress']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 43),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'i',\n",
       "   u'wonder',\n",
       "   u'how',\n",
       "   u'mani',\n",
       "   u'famili',\n",
       "   u'photo',\n",
       "   u'i',\n",
       "   u've',\n",
       "   u'ruin',\n",
       "   u'by',\n",
       "   u'walk',\n",
       "   u'in',\n",
       "   u'front',\n",
       "   u'sinc',\n",
       "   u'i',\n",
       "   u've',\n",
       "   u'been',\n",
       "   u'here']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 44),\n",
       "  'geo': (0, [-80.137196000000003, 25.956117500000001]),\n",
       "  'words': [u'connellynicol', u'jennyded', u'love', u'you']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 44),\n",
       "  'geo': (0, [-80.322630500000002, 25.940281500000001]),\n",
       "  'words': [u'soml']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 43),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 44),\n",
       "  'geo': (0, [-80.138645499999996, 26.251895000000001]),\n",
       "  'words': [u'when',\n",
       "   u'you',\n",
       "   u'and',\n",
       "   u'her',\n",
       "   u'are',\n",
       "   u'beef',\n",
       "   u'but',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'all',\n",
       "   u'love']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 45),\n",
       "  'geo': (1, [-80.2517319, 26.1905956]),\n",
       "  'words': [u'east',\n",
       "   u'ide',\n",
       "   u'hyt',\n",
       "   u'lilebunix2dop',\n",
       "   u'x',\n",
       "   u'ebunix',\n",
       "   u'vega',\n",
       "   u'cabaret',\n",
       "   u'gentlemen',\n",
       "   u's',\n",
       "   u'club']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 46),\n",
       "  'geo': (0, [-80.233328499999999, 25.782353499999999]),\n",
       "  'words': [u'thehomsguy', u'gimm', u'6', u'minut', u'to', u'shower']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 47),\n",
       "  'geo': (0, [-76.593942999999996, 24.074967000000001]),\n",
       "  'words': [u'misslicig', u'loll', u'i', u'hope', u'so']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 48),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'hentaiken', u'just', u'hmu', u'when', u'you', u'readi']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 49),\n",
       "  'geo': (1, [-81.5493554, 28.36798902]),\n",
       "  'words': [u'who',\n",
       "   u's',\n",
       "   u'readi',\n",
       "   u'to',\n",
       "   u'see',\n",
       "   u'jungl',\n",
       "   u'book',\n",
       "   u'#epcot',\n",
       "   u'#foodandwinefestival',\n",
       "   u'#waltdisneyworld',\n",
       "   u'epcot']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 51),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'the',\n",
       "   u'new',\n",
       "   u'school',\n",
       "   u'facebook',\n",
       "   u'group',\n",
       "   u'ha',\n",
       "   u'form',\n",
       "   u'into',\n",
       "   u'a',\n",
       "   u'berni',\n",
       "   u'page',\n",
       "   u'and',\n",
       "   u'i',\n",
       "   u'm',\n",
       "   u'over',\n",
       "   u'here',\n",
       "   u'like']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 52),\n",
       "  'geo': (1, [-80.15277778, 26.0725]),\n",
       "  'words': [u'just',\n",
       "   u'post',\n",
       "   u'a',\n",
       "   u'photo',\n",
       "   u'fort',\n",
       "   u'lauderdalehollywood',\n",
       "   u'intern',\n",
       "   u'airport']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 53),\n",
       "  'geo': (0, [-80.177667999999997, 25.9056055]),\n",
       "  'words': [u'i', u'hate', u'you', u'so', u'much']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 54),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 57),\n",
       "  'geo': (0, [-80.457202500000008, 25.671740999999997]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 57),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'jasonkatz999']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 57),\n",
       "  'geo': (0, [-76.593942999999996, 24.074967000000001]),\n",
       "  'words': [u'ahhfrika',\n",
       "   u'cut',\n",
       "   u'that',\n",
       "   u'nois',\n",
       "   u'ine',\n",
       "   u'ask',\n",
       "   u'you',\n",
       "   u'that']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 58),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'pro',\n",
       "   u'of',\n",
       "   u'fl',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'closer',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'equat',\n",
       "   u'con',\n",
       "   u'of',\n",
       "   u'fl',\n",
       "   u'it',\n",
       "   u's',\n",
       "   u'closer',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'equat']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 4, 58),\n",
       "  'geo': (0, [-80.294892500000003, 26.1566185]),\n",
       "  'words': [u'fvorospriv',\n",
       "   u'wassssup',\n",
       "   u'i',\n",
       "   u'm',\n",
       "   u'tri',\n",
       "   u'to',\n",
       "   u'get',\n",
       "   u'on',\n",
       "   u'the',\n",
       "   u'same',\n",
       "   u'shitttttt']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5),\n",
       "  'geo': (0, [-80.212252500000005, 26.242435499999999]),\n",
       "  'words': [u'should',\n",
       "   u've',\n",
       "   u'known',\n",
       "   u'you',\n",
       "   u'would',\n",
       "   u've',\n",
       "   u'cross',\n",
       "   u'me']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': []},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5, 1),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'just', u'wait', u'for', u'it']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5, 6),\n",
       "  'geo': (1, [-86.10984, 30.31148]),\n",
       "  'words': [u'can',\n",
       "   u'we',\n",
       "   u'go',\n",
       "   u'back',\n",
       "   u'now',\n",
       "   u'pleas',\n",
       "   u'30a',\n",
       "   u'seagrov',\n",
       "   u'beach']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5, 7),\n",
       "  'geo': (0, [-80.249772500000006, 26.270260999999998]),\n",
       "  'words': [u'andyslat',\n",
       "   u'you',\n",
       "   u'give',\n",
       "   u'your',\n",
       "   u'hard',\n",
       "   u'earn',\n",
       "   u'money',\n",
       "   u'to',\n",
       "   u'loria',\n",
       "   u'better',\n",
       "   u'to',\n",
       "   u'lose',\n",
       "   u'it',\n",
       "   u'all',\n",
       "   u'at',\n",
       "   u'one',\n",
       "   u'of',\n",
       "   u'your',\n",
       "   u'poker',\n",
       "   u'tourney',\n",
       "   u'more',\n",
       "   u'respect']},\n",
       " {'created_at': datetime.datetime(2016, 4, 1, 22, 5, 14),\n",
       "  'geo': (0, [-83.804474999999996, 27.698681999999998]),\n",
       "  'words': [u'trutherbotorng', u'burningplat']}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prc[10:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'un',\n",
       " 'american',\n",
       " 'one',\n",
       " 'koolaid',\n",
       " 'drinker',\n",
       " 'fact',\n",
       " 'i',\n",
       " 'm',\n",
       " 'welfare',\n",
       " 'never',\n",
       " 'never']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prc[0]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize(prc[0]['words'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox = [g['crds'] for g in geodata if g['pDesc'] == city][0]\n",
    "\n",
    "g = []\n",
    "F = []\n",
    "res = 30\n",
    "MTR = cell_matrix(res)\n",
    "\n",
    "for i, p in enumerate(prc):\n",
    "    if p['geo'][0] == 1:\n",
    "        g.append(p)\n",
    "\n",
    "for o in g:\n",
    "    cell = assign_cell(o, bbox, res)\n",
    "    if cell:\n",
    "        cx, cy = cell\n",
    "        F.append(o)\n",
    "        MTR[cx][cy]['objects'].append(o)\n",
    "\n",
    "for i in range(res):\n",
    "    for j in range(res):\n",
    "        progress(i*res+j, res*res, skip=1)\n",
    "        r = build_timeseries(MTR[i][j]['objects'], st, en, mins = 15, filtration=1, logging=False)\n",
    "        if r: \n",
    "            M, voc = r\n",
    "        else:\n",
    "            M, voc = None, None\n",
    "        MTR[i][j]['series'] = M\n",
    "        MTR[i][j]['voc'] = voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2v_represent(model, words):\n",
    "    WW = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            T = model[word]\n",
    "            if T.shape[0]:\n",
    "                WW.append(T)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "                \n",
    "    if len(WW):\n",
    "        return np.array(WW)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def w2v_similarity_1(model, stra, strb):\n",
    "    sm = w2v_represent(model, stra), w2v_represent(model, strb)\n",
    "    return similarity(sm[0], sm[1])/2\n",
    "\n",
    "def w2v_similarity_2(model, stra, strb):\n",
    "    w1 = w2v_represent(model, stra), w2v_represent(model, strb)\n",
    "    w2 = sim_matrix(w1[0], w1[1])\n",
    "    w3 = do_align(w2).astype(int)\n",
    "    w31, w32 = w3.nonzero()\n",
    "    w4 = np.mean([w2[z[0]][z[1]] for z in zip(w31, w32)])\n",
    "    return w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2 = w2v_similarity_2(w2v, lr[5][0]['words'], lr[5][1]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim_matrix(v1,v2):\n",
    "    if v1.shape[0] and v2.shape[0] and v1.shape[1] == v2.shape[1]:\n",
    "        sim = 1 - cdist(v1, v2, 'cosine')\n",
    "        return sim\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def similarity(v1,v2):\n",
    "    sim = sim_matrix(v1,v2)\n",
    "    thresh = 0.5\n",
    "    sk = (sim[sim > thresh])\n",
    "    sk /= sk.shape[0]\n",
    "    if type(sim) == int : \n",
    "        return 0\n",
    "    else:\n",
    "        return sum(sk)\n",
    "    \n",
    "def do_align(MT):\n",
    "    thresh = 0.4\n",
    "    align = np.zeros(MT.shape)\n",
    "    if MT.shape[0] <= MT.shape[1]:\n",
    "        maxs = np.argmax(MT,0)        \n",
    "        for i,m in enumerate(maxs):\n",
    "            if MT[maxs[i],i] >= thresh:\n",
    "                align[maxs[i],i] = 1\n",
    "    if MT.shape[0] > MT.shape[1]:\n",
    "        maxs = np.argmax(MT,1)\n",
    "        for i,m in enumerate(maxs):\n",
    "            if MT[i,maxs[i]] >= thresh:\n",
    "                align[i,maxs[i]] = 1\n",
    "    return align\n",
    "\n",
    "def sim_align(v1,v2):\n",
    "    sim = sim_matrix(v1,v2)\n",
    "    return sum(sim[allign(sim).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_correlations(cr):\n",
    "    C = [[], []]\n",
    "    for k in cr.keys():\n",
    "        for i,c in enumerate(cr[k].values()):\n",
    "            C[i].append(c[0])\n",
    "    return np.array(C), cr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = []\n",
    "for z1, i in enumerate(F):\n",
    "    for z2, j in enumerate(F):\n",
    "        if len(list_intersection(i['words'], j['words'])) > 3 and i['words']!=j['words'] and z1!=z2:\n",
    "            lr.append((i,j))\n",
    "            if len(lr) > 1000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wavesim(u,v):\n",
    "    cors = {}\n",
    "    \n",
    "    for intr in list_intersection(u['words'], v['words']):\n",
    "        try:\n",
    "            scl = mxscl - spatialscale(eu_distance(u['geo'][1], v['geo'][1]), 0, mxrang)\n",
    "\n",
    "            c1x, c1y = assign_cell(u, bbox, res)\n",
    "            id1 = MTR[c1x][c1y]['voc'][intr]\n",
    "            ser1 = MTR[c1x][c1y]['series'][id1]\n",
    "            dw1 = DWTransform(ser1, scl)\n",
    "\n",
    "\n",
    "            c2x, c2y = assign_cell(v, bbox, res)\n",
    "            id2 = MTR[c2x][c2y]['voc'][intr]\n",
    "            ser2 = MTR[c2x][c2y]['series'][id2]\n",
    "            dw2 = DWTransform(ser2, scl)\n",
    "            \n",
    "            ss = [np.concatenate(dw1),np.concatenate(dw2)]\n",
    "            cors[intr]= {'pearson': pearsonr(ss[0], ss[1]), 'spearman': spearmanr(ss[0], ss[1])}\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    return cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalpair(a,b):\n",
    "    c, keys = eval_correlations(wavesim(a, b))\n",
    "    w1 = w2v_similarity_1(w2v, a, b)\n",
    "    w2 = w2v_similarity_2(w2v, a, b)\n",
    "    t1 = tf_similarity(TF, a, b)\n",
    "\n",
    "    A = np.array([keys, w1*c ,w2*c, t1*c])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Lines(object):\n",
    "    def __init__(self, input):\n",
    "        self.filenames = np.atleast_1d(input)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for filename in self.filenames:\n",
    "            try:\n",
    "                for line in open(filename, 'r'):\n",
    "                    try:\n",
    "                        yield line\n",
    "                    except:\n",
    "                        yield []\n",
    "            except:\n",
    "                yield[]\n",
    "\n",
    "    def count_samples(self):\n",
    "        cnt = 0\n",
    "        for filename in self.filenames:\n",
    "            for line in open(filename, 'r'):\n",
    "                cnt += 1\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lins = Lines(['/ssd/raw_text_datasets/'+f for f in os.listdir('/ssd/raw_text_datasets')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF = TfidfVectorizer('content', decode_error='ignore', stop_words=sw, token_pattern=tok_regex, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_similarity(model, a, b):\n",
    "        return 1 - cosine(model.transform([' '.join(a['words'])]).toarray(),model.transform([' '.join(b['words'])]).toarray())\n",
    "\n",
    "def spatialscale(d, minrang, maxrang, st = mxscl):\n",
    "    lspace = np.logspace(minrang, maxrang, st, base=np.e)\n",
    "    r = np.e**d\n",
    "    for i, s in enumerate(lspace):\n",
    "        if s > r: break\n",
    "    return i\n",
    "\n",
    "def eu_distance(u, v):\n",
    "    return vincenty(u[::-1], v[::-1]).kilometers\n",
    "\n",
    "def pearsoncora(u,v):\n",
    "    return pearsonr(u,v)[0]\n",
    "\n",
    "def pearsoncorb(u,v):\n",
    "    return pearsonr(u,v)[1]\n",
    "\n",
    "def DWTransform(ts, level, plt = False):\n",
    "    ca = ts\n",
    "    for l in range(level):\n",
    "        ca, cd = pywt.dwt(ca, 'haar', mode='zero')\n",
    "    if plt:\n",
    "        plot(ca, 0)\n",
    "        plot(cd, 0)\n",
    "    return ca, cd\n",
    "\n",
    "mxrang = eu_distance(bbox[0:2], bbox[2:4])\n",
    "mnrang = min((bbox[3]-bbox[1])/res, (bbox[2]-bbox[0])/res)\n",
    "mnrang = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_similarity(TF, lr[0][0], lr[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec.load('assets/w2v/w2v_model_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vt = gensim.models.Word2Vec.load('assets/w2v/w2v_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = MC.shape[0]\n",
    "pdist = np.zeros((z, z))\n",
    "\n",
    "for i in range(z):\n",
    "    for j in range(z):\n",
    "        if not pdist[i][j]:\n",
    "            progress(i*z + j, z*z, skip = 1000)\n",
    "            r = np.array(pearsonr(MC[i], MC[j])[1])\n",
    "            pdist[i][j] = r\n",
    "            pdist[j][i] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dump_obj(TF, 'assets/TF_VECTORISER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show(M, n, l = 1):\n",
    "    print n, voc[n], '----------------------------------->>'\n",
    "    plot(M[n], 1)\n",
    "    \n",
    "    print 'DWT LEVEL', l ,'---------------------------------->>'\n",
    "    da, dd = DWTransform(M[n], l, plt = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = load_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = pairwise_distances(MC, metric=pearsoncorb, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from stopwords import stopwords\n",
    "def load_stop_words():\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    stop_words.extend(stopwords)\n",
    "    return set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def w2v_transform(W, model, dim = 256):\n",
    "    st = datetime.now()\n",
    "    l = len(W)\n",
    "    M = []\n",
    "    for i, sent in enumerate(W):\n",
    "        words = sent\n",
    "        b = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                b.append(model[word])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        B = np.array(b)\n",
    "        if not isinstance(B, np.ndarray):\n",
    "            B = np.zeros((1, dim))\n",
    "\n",
    "        M.append(B)\n",
    "        progress(i, l)\n",
    "        \n",
    "    M = np.array(M)\n",
    "    F = []\n",
    "    idx = []\n",
    "    for i, m in enumerate(M):\n",
    "        if m.shape[0]:\n",
    "            F.append(m)\n",
    "            idx.append(i)\n",
    "        \n",
    "    \n",
    "    print '\\ntransforming took', datetime.now() - st\n",
    "    return np.array(F), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr_dist(M):\n",
    "    dim = M.shape[0]\n",
    "    R = np.zeros((dim,dim))\n",
    "    c = 0\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            progress(i*dim + j, dim*dim, skip = 100)\n",
    "            if i == j:\n",
    "                R[i][j] = 0\n",
    "            elif not R[i][j] and not R[j][i]:\n",
    "                r = DTWDistance(M[i], M[j])\n",
    "                c += 1\n",
    "                R[i][j] = r\n",
    "                R[j][i] = r\n",
    "    return R, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = datetime.now()\n",
    "s_sim = pairwise_distances(P, metric=DTW_hybrid, n_jobs=12)\n",
    "en = datetime.now()\n",
    "print str(en-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "windows = np.array(range(P.shape[1]))\n",
    "mv_wind_size = int(0.05*len(windows))\n",
    "\n",
    "for term_n in range(P.shape[0]):\n",
    "    print 'term: >>>', voc[ind[term_n]]\n",
    "    plt.plot(windows, P[term_n], 'b-', label='label here')\n",
    "    plt.plot(windows, movingaverage(P[term_n], mv_wind_size), 'r-', label='label here')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimated_autocorrelation(x):\n",
    "    n = len(x)\n",
    "    variance = x.var()\n",
    "    x = x-x.mean()\n",
    "    r = np.correlate(x, x, mode = 'full')[-n:]\n",
    "    assert np.allclose(r, np.array([(x[:n-k]*x[-(n-k):]).sum() for k in range(n)]))\n",
    "    result = r/(variance*(np.arange(n, 0, -1)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "react = ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
